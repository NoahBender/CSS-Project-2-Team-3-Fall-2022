{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2bf4be1",
   "metadata": {},
   "source": [
    "# Computational Social Science Project #2 \n",
    "\n",
    "*Group number:* \n",
    "\n",
    "*Group members:*   \n",
    "\n",
    "*Semester:* Fall 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8fb6f6",
   "metadata": {},
   "source": [
    "Below we fill in some of the code you might use to answer some of the questions. Here are some additional resources for when you get stuck:\n",
    "* Code and documentation provided in the course notebooks  \n",
    "* [Markdown cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to help with formatting the Jupyter notebook\n",
    "* Try Googling any errors you get and consult Stack Overflow, etc. Someone has probably had your question before!\n",
    "* Send KQ a pull request on GitHub flagging the syntax that's tripping you up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f66f6a",
   "metadata": {},
   "source": [
    "## 1. Introduction/Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a3947",
   "metadata": {},
   "source": [
    "#### a) Import relevant libraries\n",
    "Add the other libraries you need for your code below and/or as you go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries you might need here \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# use random seed for consistent results \n",
    "np.random.seed(273)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19dae8c",
   "metadata": {},
   "source": [
    "#### b) Read in and inspect data frame \n",
    "Read in the data frame and look at some of its attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8073f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(______, \n",
    "                       #CountyFips needs to be a string so leading 0 isn't dropped (this is only if you want to make choropleth map): \n",
    "                       dtype={\"CountyFIPS\": str}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52858c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the dimensions of the diabetes data frame\n",
    "print('shape: ', diabetes.______) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39985523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100) # tells pandas how many rows to display when printing so results don't get truncated\n",
    "\n",
    "# look at the data types for each column in diabetes df \n",
    "print('data types:', diabetes.______)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcc077",
   "metadata": {},
   "source": [
    "Immediately, we see that some of the features that should be numeric (e.g., Diabetes_Number, Obesity_Number,  and Physical_Inactivity_Number) are not. We can check to see what the non-numeric values are in a column where we are expecting numeric information with a combination of `str.isnumeric()` and `unique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785eeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return rows where the column \"Diabetes_Number\" is non-numeric and get the unique values of these rows\n",
    "# the \"~\" below in front of diabetes negates the str.isnumeric() so it only takes non-numeric values\n",
    "print(diabetes[~diabetes[______].str.isnumeric()][______].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same as above, but for \"Obesity_Number\" :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829afe3",
   "metadata": {},
   "source": [
    "The values contained in the two columns above making them objects (rather than integers) appear to be strings like \"No Data\" and \"Suppressed.\" Let's drop those rows in the next section, and also recode Physical_Inactivity_Number to be an integer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d5c0e",
   "metadata": {},
   "source": [
    "#### c. Recode variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c96e7",
   "metadata": {},
   "source": [
    "Convert 'Diabetes_Number', 'Obesity_Number', and 'Physical_Inactivity_Number' to integers below so we can use them in our analysis. Also fill in the object type we want to recode 'sex and age_total population_65 years and over_sex ratio (males per 100 females)' to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes\n",
    "# keep only useful info about our target feature, i.e., where diabetes_number not = 'Suppressed'\n",
    "diabetes = diabetes[diabetes['Diabetes_Number']!=\"Suppressed\"]  # note that the inside reference to the diabetes df identifies the column, and the outer calls specific rows according to a condition \n",
    "\n",
    "# use the astype method on Diabetes_Number to convert it to an integer...if you are not sure, what does the astype() documentation tell you are possible arguments? \n",
    "diabetes['Diabetes_Number'] = diabetes['Diabetes_Number'].astype(______) \n",
    "\n",
    "# Obesity\n",
    "\n",
    "\n",
    "\n",
    "# Physical Inactivity\n",
    "\n",
    "\n",
    "\n",
    "# 65+ sex ratio had one \"-\" in it so let's drop that row first\n",
    "diabetes = diabetes[diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)']!= \"-\"]\n",
    "# change to numeric (specifically, integer or float?) from string (because originally included the \"-\" )\n",
    "diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)'] = diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)'].astype(______)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a0f933",
   "metadata": {},
   "source": [
    "We should probably scale our count variables to be proportional to county population. We create the list 'rc_cols' to select all the features we want to rescale, and then use the `.div()` method to avoid typing out every single column we want to recode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select count variables to rc to percentages; make sure we leave out ratios and our population variable b/c these don't make sense to scale by population\n",
    "rc_cols = [col for col in ______.columns if col not in ['County', 'State', 'CountyFIPS', \n",
    "                                                        'sex and age_total population_65 years and over_sex ratio (males per 100 females)', 'sex and age_total population_sex ratio (males per 100 females)', 'sex and age_total population_18 years and over_sex ratio (males per 100 females)',  \n",
    "                                                        'race_total population']]\n",
    "           \n",
    "diabetes[______] = diabetes[______].apply(pd.to_numeric, errors='coerce') # recode all selected columns to numeric\n",
    "\n",
    "# divide all columns but those listed above by total population to calculate rates\n",
    "diabetes[______] = diabetes[______].div(______['race_total population'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c09414",
   "metadata": {},
   "source": [
    "Let's check our work. Are all rates bounded by 0 and 1 as expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad895e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# inspect recoded values\n",
    "diabetes_summary = ______.describe().transpose() # note we use the transpose method rather than .T because this object is not a numpy array\n",
    "  \n",
    "# check recoding \n",
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', None): \n",
    "    display(diabetes_summary.iloc[ : ,[0,1,3,7]]) # select which columns in the summary table we want to present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2bd37",
   "metadata": {},
   "source": [
    "#### d. Check for duplicate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d982ba",
   "metadata": {},
   "source": [
    "There are a lot of columns in this data frame. Let's see if there are any are duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11428ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used Google to figure this out, and adapted this example for our purposes:  \n",
    "# source: https://thispointer.com/how-to-find-drop-duplicate-columns-in-a-dataframe-python-pandas/ \n",
    "def getDuplicateColumns(df):\n",
    "    '''\n",
    "    Get a list of duplicate columns.\n",
    "    It will iterate over all the columns in dataframe and find the columns whose contents are duplicate.\n",
    "    :param df: Dataframe object\n",
    "    :return: List of columns whose contents are duplicates.\n",
    "    '''\n",
    "    duplicateColumnNames = set()\n",
    "    # Iterate over all the columns in dataframe\n",
    "    for x in range(df.shape[1]):\n",
    "        # Select column at xth index.\n",
    "        col = df.iloc[:, x]\n",
    "        # Iterate over all the columns in DataFrame from (x+1)th index till end\n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "            # Select column at yth index.\n",
    "            otherCol = df.iloc[:, y]\n",
    "            # Check if two columns at x 7 y index are equal\n",
    "            if col.equals(otherCol):\n",
    "                duplicateColumnNames.add(df.columns.values[y])\n",
    "    return list(duplicateColumnNames)\n",
    "\n",
    "duplicateColumnNames = list(getDuplicateColumns(______))\n",
    "print('Duplicate Columns are as follows: ')\n",
    "duplicateColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c966ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now drop list of duplicate features from our df using the .drop() method\n",
    "diabetes = diabetes.drop(columns=______) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854ac28",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2dfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your EDAs and interpretations in this section "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e38866",
   "metadata": {},
   "source": [
    "## 3. Prepare to Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc4c67",
   "metadata": {},
   "source": [
    "### 3.1 Finalize Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d14a2",
   "metadata": {},
   "source": [
    "We've already cleaned up the data, but we can make a few more adjustments before partitioning the data and training models. Let's recode 'State' to be a categorical variable using `pd.get_dummies` and drop 'County' using `.drop()` because 'CountyFIPS' is already a unique identifier for the county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38225afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy features out of 'State' , which might be related to diabetes rates \n",
    "diabetes_clean = pd.get_dummies(______, \n",
    "                               columns = [______],  \n",
    "                               drop_first = True) # only create 49 dummies by dropping first in category\n",
    "\n",
    "# drop 'County' variable\n",
    "diabetes_clean = diabetes_clean.drop(labels = ['County'],\n",
    "                               axis = ______) # which axis tells python we want to drop columns rather than index rows?\n",
    "\n",
    "# look at first 10 rows of new data frame \n",
    "diabetes_clean.______ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc43c0",
   "metadata": {},
   "source": [
    "### 3.2/3.3 Partition Data and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b225a1",
   "metadata": {},
   "source": [
    "Now, we will partition our data to prepare it for the training process. We will use 60% train—20% validation—20% test in this case. More data in the training set lowers bias, but then increases variance in the validation/test sets. Balancing between bias and variance with choice of these set sizes is important as we want to ensure that there is enough data to train on to get good predictions, but also want to make sure our hold-out sets are representative enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set y \n",
    "y = ______\n",
    "\n",
    "# X (everything except diabetes, our target)\n",
    "X = ______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac53ca9",
   "metadata": {},
   "source": [
    "We should also preprocess our data. Using the `preprocessing` module from sklearn, let's scale our features so that they are mean-centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa70463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0158fbe",
   "metadata": {},
   "source": [
    "We can also get rid of the 0 variance features using the `VarianceThreshold()` method from `feature_selection`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af378860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "\n",
    "selector = feature_selection.VarianceThreshold(0)\n",
    "X = selector.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b83942",
   "metadata": {},
   "source": [
    "And finally, let's split our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test, so how do we create a 60-20-20 train-validate-test split? \n",
    "\n",
    "X_train, X_test, y_train, y_test = ______\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = ______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7d3a9",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc13e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your five models in this section "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06845171",
   "metadata": {},
   "source": [
    "## 5. Validate and Refine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use X_validation and y_validation data sets to evaluate and refine your models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d55c5",
   "metadata": {},
   "source": [
    "## 6. Discussion Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac2e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert responses for discussion Qs here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
